# -*- coding: utf-8 -*-
"""Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qaGn2CrLD1qW0LYccQVwrkKiBk2FK9QC
"""

# Kaggle API kurulumu
!mkdir -p ~/.kaggle
from google.colab import files
files.upload()   # buradan kaggle.json yükle

!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Veri setini indir
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

# Zip aç
!unzip -q chest-xray-pneumonia.zip -d chest_xray

import os

# chest_xray klasörünü listele
print("Ana klasör:", os.listdir())

# chest_xray altındaki içerikler
if "chest_xray" in os.listdir():
    print("chest_xray içeriği:", os.listdir("chest_xray"))

import os

# Ana klasör
base_dir = "chest_xray"

# Eğer içinde tekrar chest_xray klasörü varsa, düzeltelim
if "chest_xray" in os.listdir(base_dir):
    base_dir = os.path.join(base_dir, "chest_xray")

# Yol tanımları
train_dir = os.path.join(base_dir, "train")
test_dir  = os.path.join(base_dir, "test")
val_dir   = os.path.join(base_dir, "val")

print("Train klasörü:", train_dir)
print("Test klasörü :", test_dir)
print("Val klasörü  :", val_dir)

# Son kontrol
print("Train içeriği:", os.listdir(train_dir))

train_datagen = ImageDataGenerator(rescale=1./255,
                                   validation_split=0.1,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

train_set = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    subset='training',
    shuffle=True  # Önemli!
)

val_set = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    subset='validation',
    shuffle=True
)

from collections import Counter

print("Train sınıf dağılımı:", Counter(train_set.classes))
print("Validation sınıf dağılımı:", Counter(val_set.classes))

from sklearn.utils import class_weight
import numpy as np

# Class weight hesapla
weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_set.classes),
    y=train_set.classes
)

class_weights = dict(enumerate(weights))
print("Class Weights:", class_weights)



import tensorflow as tf
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from collections import Counter
import numpy as np
from sklearn.utils import class_weight # Import class_weight from sklearn.utils

# ----------------------------
# 1️⃣ Data Augmentation
# ----------------------------
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    brightness_range=[0.8,1.2]
)

train_set = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_set = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    subset='validation',
    shuffle=False
)

# ----------------------------
# 2️⃣ Class Weights (kontrol)
# ----------------------------
weights = {i:w for i,w in enumerate(
    class_weight.compute_class_weight(  # Use class_weight from sklearn.utils
        class_weight='balanced',
        classes=np.unique(train_set.classes),
        y=train_set.classes
    )
)}
print("Class Weights:", weights)
print("Train classes:", Counter(train_set.classes))
print("Val classes:", Counter(val_set.classes))

# ----------------------------
# 3️⃣ DenseNet121 Base Model
# ----------------------------
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))
base_model.trainable = False  # İlk başta dondur

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# ----------------------------
# 4️⃣ EarlyStopping
# ----------------------------
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# ----------------------------
# 5️⃣ Model Training
# ----------------------------
history = model.fit(
    train_set,
    validation_data=val_set,
    epochs=20,
    class_weight=weights,
    callbacks=[early_stop]
)

# ----------------------------
# 6️⃣ Fine-tuning (opsiyonel)
# ----------------------------
base_model.trainable = True
for layer in base_model.layers[:-50]:
    layer.trainable = False

model.compile(
    optimizer=Adam(1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

history_finetune = model.fit(
    train_set,
    validation_data=val_set,
    epochs=10,
    class_weight=weights,
    callbacks=[early_stop]
)

import matplotlib.pyplot as plt

# ----------------------------
# 1️⃣ Train ve Validation Accuracy
# ----------------------------
plt.figure(figsize=(12,5))
plt.plot(history.history['accuracy'], label='Train Accuracy (pretrain)')
plt.plot(history.history['val_accuracy'], label='Val Accuracy (pretrain)')

if 'history_finetune' in locals():  # fine-tuning varsa
    plt.plot(history_finetune.history['accuracy'], label='Train Accuracy (finetune)')
    plt.plot(history_finetune.history['val_accuracy'], label='Val Accuracy (finetune)')

plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# ----------------------------
# 2️⃣ Train ve Validation Loss
# ----------------------------
plt.figure(figsize=(12,5))
plt.plot(history.history['loss'], label='Train Loss (pretrain)')
plt.plot(history.history['val_loss'], label='Val Loss (pretrain)')

if 'history_finetune' in locals():
    plt.plot(history_finetune.history['loss'], label='Train Loss (finetune)')
    plt.plot(history_finetune.history['val_loss'], label='Val Loss (finetune)')

plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# ----------------------------
# 1️⃣ Test set datagenerator
# ----------------------------
test_datagen = ImageDataGenerator(rescale=1./255)

test_set = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    shuffle=False  # Önemli, doğru confusion matrix için
)

# ----------------------------
# 2️⃣ Tahminler
# ----------------------------
y_pred_prob = model.predict(test_set)
y_pred = (y_pred_prob > 0.5).astype(int)  # 0/1 olarak dönüştür
y_true = test_set.classes

# ----------------------------
# 3️⃣ Confusion Matrix
# ----------------------------
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ----------------------------
# 4️⃣ Classification Report
# ----------------------------
report = classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA'])
print(report)

from sklearn.metrics import roc_curve, auc

# Tahmin olasılıkları
y_pred_prob = model.predict(test_set).ravel()  # Flatten

# ROC ve AUC hesapla
fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Çizim
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

